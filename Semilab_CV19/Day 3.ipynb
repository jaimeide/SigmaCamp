{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals:\n",
    "- Corner and Edge Detection (15 min)\n",
    "- Template matching (15 min)\n",
    "- [  ] Show video of tracking and run demo (15 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_rgb(img):\n",
    "    # Will expect RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title('Look weird if you entered BGR...')\n",
    "    #plt.show()\n",
    "    \n",
    "def show_bgr(img):\n",
    "    # Will expect RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    #plt.show()\n",
    "    \n",
    "def show_cv2(img):\n",
    "    # Input should be BGR\n",
    "    cv2.imshow('image',img)\n",
    "    \n",
    "    cv2.waitKey(0) # Closes with any key\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def display(img,cmap=None):\n",
    "    # Create with larger size\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img,cmap)\n",
    "    \n",
    "    #from skimage.exposure import rescale_intensity\n",
    "\n",
    "def convolve(image, kernel):\n",
    "    # 1) Grab the spatial dimensions of the image, along with\n",
    "    # the spatial dimensions of the kernel\n",
    "    (iH, iW) = image.shape[:2]\n",
    "    (kH, kW) = kernel.shape[:2]\n",
    "    \n",
    "    # 2) Allocate memory for the output image, taking care to\n",
    "    # \"pad\" the borders of the input image so the spatial\n",
    "    # size (i.e., width and height) are not reduced\n",
    "    # padding: if ur image is 10x10 and kernel is 3x3, padded image should be 12x12\n",
    "    pad = (kW - 1) // 2 # if kernel width is kW=3, this will return  pad=1. \"//\" returns the quocient\n",
    "    image = cv2.copyMakeBorder(image, pad, pad, pad, pad,cv2.BORDER_REPLICATE)\n",
    "    # Output image\n",
    "    output = np.zeros((iH, iW), dtype=\"float32\")\n",
    "    \n",
    "    # 3) Loop over the input image, \"sliding\" the kernel across\n",
    "    # each (x, y)-coordinate from left-to-right and top to\n",
    "    # bottom\n",
    "    for y in np.arange(pad, iH + pad):\n",
    "        for x in np.arange(pad, iW + pad):\n",
    "            # 4) Extract the ROI of the image by extracting the\n",
    "            # *center* region of the current (x, y)-coordinates\n",
    "            # dimensions\n",
    "            roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    " \n",
    "            # 5) Perform the actual convolution by taking the\n",
    "            # element-wise multiplicate between the ROI and\n",
    "            # the kernel, then summing the matrix\n",
    "            k = (roi * kernel).sum()\n",
    " \n",
    "            # 6) Store the convolved value in the output (x,y)-\n",
    "            # coordinate of the output image\n",
    "            output[y - pad, x - pad] = k\n",
    "            \n",
    "    # 7) Rescale the output image to be in the range [0, 255]\n",
    "    #output = rescale_intensity(output, in_range=(0, 255))\n",
    "    #output = (output * 255).astype(\"uint8\")\n",
    " \n",
    "    # return the output image\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection\n",
    "\n",
    "You can try corner and edge detection using the convolution function you wrote and/or use the built-in OpenCV functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image\n",
    "chess = cv2.imread('chess.png')\n",
    "chess0 = cv2.imread('chess.png',0)\n",
    "#chess = cv2.cvtColor(flat_chess,cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(7,10))\n",
    "plt.subplot(1,2,1)\n",
    "show_bgr(chess)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(chess0,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Laplacian kernel used to detect edge-like\n",
    "# regions of an image\n",
    "laplacian = np.array((\n",
    "[0, 1, 0],\n",
    "[1, -4, 1],\n",
    "[0, 1, 0]), dtype=\"int\")\n",
    " \n",
    "# construct the Sobel x-axis kernel\n",
    "sobelX = np.array((\n",
    "[-1, 0, 1],\n",
    "[-2, 0, 2],\n",
    "[-1, 0, 1]), dtype=\"int\")\n",
    " \n",
    "# construct the Sobel y-axis kernel\n",
    "sobelY = np.array((\n",
    "[-1, -2, -1],\n",
    "[0, 0, 0],\n",
    "[1, 2, 1]), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolve using sobelY: why we have this result?\n",
    "out = convolve(chess0,sobelY)\n",
    "plt.imshow(out,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolve using X: : why we have this result?\n",
    "out = convolve(chess0,sobelX)\n",
    "plt.imshow(out,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the other edges? How to get them?\n",
    "# You can actually do that by modifying the previous kernels.\n",
    "# Hint: Just invert them ;)\n",
    "\n",
    "# construct the Sobel x-axis kernel (inverted)\n",
    "sobelXi = np.array((\n",
    "[1, 0, -1],\n",
    "[2, 0, -2],\n",
    "[1, 0, -1]), dtype=\"int\")\n",
    " \n",
    "# construct the Sobel y-axis kernel (inverted)\n",
    "sobelYi = np.array((\n",
    "[1, 2, 1],\n",
    "[0, 0, 0],\n",
    "[-1,-2,-1]), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try those inverted kernels: did you get what you wanted?\n",
    "out = convolve(chess0,sobelXi)\n",
    "plt.imshow(out,cmap='gray')\n",
    "out = convolve(chess0,sobelYi)\n",
    "plt.imshow(out,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corner Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to detect corner using the kernels?\n",
    "- SOLUTION: Corner detection is where the X-grad and Y-grad meet! That's the intuition behind most popular method Harris-Corner detection (Shi-Tomasi detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cornerHarris Function**\n",
    "\n",
    "*  src: Input single-channel 8-bit or floating-point image.\n",
    "*  dst: Image to store the Harris detector responses. It has the type CV_32FC1 and the same size as src .\n",
    "*  blockSize: Neighborhood size (see the details on #cornerEigenValsAndVecs ).\n",
    "*  ksize: Aperture parameter for the Sobel operator.\n",
    "*  k: Harris detector free parameter. See the formula in DocString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Gray Scale Image to Float Values\n",
    "gray = np.float32(chess0)\n",
    "\n",
    "# Corner Harris Detection\n",
    "dst = cv2.cornerHarris(src=gray,blockSize=2,ksize=3,k=0.04)\n",
    "\n",
    "# result is dilated for marking the corners, not important to actual corner detection\n",
    "# this is just so we can plot out the points on the image shown\n",
    "#dst = cv2.dilate(dst,None)\n",
    "\n",
    "plt.imshow(dst,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the detected corners in the original image\n",
    "chess = cv2.cvtColor(chess,cv2.COLOR_BGR2RGB)\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "chess[dst>0.01*dst.max()]=[255,0,0]\n",
    "\n",
    "plt.imshow(chess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Matching\n",
    "\n",
    "Template matching is the most fundamental method for object detection. The idea is simple. Given a template image, find it in the image! How would you implement it? By subtraction? That's possible, but it would affected by intensity variations. Most common way is to use correlation metric. However, you can actually even use the convolution function you just coded!\n",
    "\n",
    "Before you try to do it, let's illustrate the intuition behind using convolution for template matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an image of a 3x3 square\n",
    "img = np.zeros([10,10])\n",
    "img[4:7,4:7] = 255\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if you convolve this image?\n",
    "convolve(img,np.ones([3,3])).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly! Whenever you have a part of the image matching the kernel image, it will generate the highest values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ ] EXERCISE: Write a code to find Waldo, given the image and the actual image of Waldo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given Where is Waldo image\n",
    "where = cv2.imread('whereiswaldo1.jpg')\n",
    "where_rgb = cv2.cvtColor(where,cv2.COLOR_BGR2RGB)\n",
    "display(where_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the template\n",
    "waldo = cv2.imread('waldo.jpg')\n",
    "waldo_rgb = cv2.cvtColor(waldo,cv2.COLOR_BGR2RGB)\n",
    "display(waldo_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**: You can try using your convolution function, \n",
    "however, you might have to adapt it to accept non-square shape kernels. You can try any other approach as well. To keep it simple, let's use the built-in function for template matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image. You can just work with BGR images.\n",
    "where = cv2.imread('whereiswaldo1.jpg')\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR','cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "method = eval(methods[0])\n",
    "res = cv2.matchTemplate(where,waldo,method)\n",
    "# Show the output image: how does it look like? Can you find Waldo there?\n",
    "plt.imshow(res,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing a rectangle in the max point\n",
    "To really know whether the method is working, we can draw a box around the point with the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dim \n",
    "height, width,channels = waldo.shape\n",
    "\n",
    "# Grab the Max and Min values, plus their locations\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "# Set up drawing of Rectangle\n",
    "top_left = max_loc\n",
    "# Assign the Bottom Right of the rectangle\n",
    "bottom_right = (top_left[0] + width, top_left[1] + height)\n",
    "\n",
    "# Draw the Red Rectangle\n",
    "cv2.rectangle(where,top_left, bottom_right,color=(0,255,0),thickness=3)\n",
    "\n",
    "# save image\n",
    "status = cv2.imwrite('found_WALDO.png',where)\n",
    "print(\"Image written to file-system : \",status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the saved image or show check it here. Did it work?\n",
    "show_cv2(where)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ ] EXERCISE (EXTRA)\n",
    "Use the template matching approach to find the most red car in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
